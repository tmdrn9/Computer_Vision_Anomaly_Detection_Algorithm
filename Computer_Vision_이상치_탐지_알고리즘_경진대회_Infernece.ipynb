{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHipUByj0VaN"
      },
      "source": [
        "# **Computer Vision 이상치 탐지 알고리즘 경진대회**\n",
        "\n",
        "start : 220401\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLnP7Yp2M2x7"
      },
      "source": [
        "# Import module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zwB1emC39P1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL \n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEQ2jFXo7hzu"
      },
      "source": [
        "# Set drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beMLRmMK5ZA1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount._DEBUG = True\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BElO2hfb6va2"
      },
      "outputs": [],
      "source": [
        "os.chdir('./drive/MyDrive/이상치/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCAdaZ3O39K0"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "    \n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtN7vi_m6NDA"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-TsLo2f6yk0"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# !unzip \"./open.zip\" -d \"/content/drive/MyDrive/Dacon/Computer Vision 이상치 탐지 알고리즘 경진대회/data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "910_ooglOC_M"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# !unzip \"./data/train.zip\" -d \"/content/drive/MyDrive/이상치/data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d74MZWzDOQPR"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "!unzip \"./data/test.zip\" -d \"/content/drive/MyDrive/이상치/data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8--KhQV39G2"
      },
      "outputs": [],
      "source": [
        "train_x = sorted(glob('./data/train/*.png'))\n",
        "test = sorted(glob('./data/test/*.png'))\n",
        "train_csv = pd.read_csv(\"./data/train_df.csv\")\n",
        "train_label = train_csv[\"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUWpkidO5Ada"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "737_mYwudLdl"
      },
      "outputs": [],
      "source": [
        "label_unique = sorted(np.unique(train_label))\n",
        "\n",
        "label_unique_dir = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
        "\n",
        "train_Y = [label_unique_dir[k] for k in train_label]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_dir,transform=None):\n",
        "        super().__init__()\n",
        "        self.transforms = transform\n",
        "        self.x_img = x_dir \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_img)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_img = self.x_img[idx]\n",
        "\n",
        "        x_img = cv2.imread(x_img)\n",
        "        x_img = cv2.cvtColor(x_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transforms:\n",
        "            augmented = self.transforms(image=x_img)\n",
        "            x_img = augmented['image']\n",
        "\n",
        "        return x_img"
      ],
      "metadata": {
        "id": "_wvy_bZK_Jj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eosoEmD_cFnm"
      },
      "outputs": [],
      "source": [
        "! pip install albumentations==0.4.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5s9JpzeYtmo"
      },
      "outputs": [],
      "source": [
        "import albumentations\n",
        "import albumentations.pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_inputsize(inputsize):\n",
        "  return albumentations.Compose([\n",
        "      albumentations.Resize(inputsize, inputsize),\n",
        "      albumentations.augmentations.transforms.Normalize(mean=(0.5,), std=(0.5,), p=1.0),\n",
        "      albumentations.pytorch.transforms.ToTensorV2(p=1.0)\n",
        "      ])"
      ],
      "metadata": {
        "id": "AxOpjpnI4WpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4f1-ecCBK6G"
      },
      "outputs": [],
      "source": [
        "batch_size=32\n",
        "test_dataset224 = TestDataset(test,transform_inputsize(224))\n",
        "test_loader224 = torch.utils.data.DataLoader(test_dataset224, shuffle=False, batch_size=batch_size)\n",
        "test_dataset300 = TestDataset(test,transform_inputsize(300))\n",
        "test_loader300 = torch.utils.data.DataLoader(test_dataset300, shuffle=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIRvokJRc_ov"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "import timm"
      ],
      "metadata": {
        "id": "RawPwu8aywOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "swin_tiny_patch4_window7_224 = timm.create_model('swin_tiny_patch4_window7_224',pretrained=True,num_classes=88,in_chans=3)\n",
        "swin_tiny_patch4_window7_224.load_state_dict(torch.load('swin_tiny_patch4_window7_224.pt'))"
      ],
      "metadata": {
        "id": "QbpqzjaYw9l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "efficientnetB2 = EfficientNet.from_pretrained('efficientnet-b2', num_classes=88)\n",
        "efficientnetB2.load_state_dict(torch.load('efficientnet-b2.pt'))"
      ],
      "metadata": {
        "id": "Xj87mk9MUXCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnetB0 = EfficientNet.from_pretrained('efficientnet-b0', num_classes=88)\n",
        "efficientnetB0.load_state_dict(torch.load('efficientnet-b0.pt'))"
      ],
      "metadata": {
        "id": "rXHf5ISTUW-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixnet_s=timm.create_model('mixnet_s',pretrained=True,num_classes=88,in_chans=3)\n",
        "mixnet_s.load_state_dict(torch.load('mixnet_s.pt'))"
      ],
      "metadata": {
        "id": "g5EtUAyH6sRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbRHpKkd5nmP"
      },
      "source": [
        "# Inference v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLWZVQm60xq9"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "model.eval()\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x,_ in tqdm(test_loader):\n",
        "        x = x.to(device)\n",
        "        pred = model(x)\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK489J6SFrMz"
      },
      "source": [
        "# Inference v2 (TTA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnIJrzNFFx05"
      },
      "outputs": [],
      "source": [
        "import ttach as tta\n",
        "\n",
        "tta_transforms = tta.Compose(\n",
        "    [\n",
        "        tta.Rotate90(angles=[0, 180]),\n",
        "        tta.Multiply(factors=[0.9, 1, 1.1]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "tta_model1 = tta.ClassificationTTAWrapper(swin_tiny_patch4_window7_224, tta_transforms)\n",
        "tta_model2 = tta.ClassificationTTAWrapper(seresnext50_32x4d, tta_transforms) \n",
        "tta_model3 = tta.ClassificationTTAWrapper(efficientnetB2, tta_transforms) \n",
        "tta_model4 = tta.ClassificationTTAWrapper(efficientnetB0, tta_transforms) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmiMRXaWFxxE"
      },
      "outputs": [],
      "source": [
        "tta_model1.to(device)\n",
        "tta_model1.eval()\n",
        "tta_model2.to(device)\n",
        "tta_model2.eval()\n",
        "tta_model3.to(device)\n",
        "tta_model3.eval()\n",
        "tta_model4.to(device)\n",
        "tta_model4.eval()\n",
        "\n",
        "\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x,_ in tqdm(test_loader):\n",
        "        x = x.to(device)\n",
        "        pred1 = tta_model1(x)\n",
        "        pred2 = tta_model2(x)\n",
        "        pred3 = tta_model3(x)\n",
        "        pred4 = tta_model4(x)\n",
        "        pred=(pred1+pred2+pred3+pred4)/4\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference v3(TTA+difference input size)"
      ],
      "metadata": {
        "id": "X7SZxCfMxN3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/qubvel/ttach"
      ],
      "metadata": {
        "id": "Lg_vx_nTxWnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ttach"
      ],
      "metadata": {
        "id": "c8wxhzP161y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ttach.Scale함수는 input output 크기가 달라서 같게 함수 수정\n",
        "class myScale(ttach.Scale):\n",
        "    def apply_aug_image(self, image, scale=1, **kwargs):\n",
        "        image_h,image_w=image.shape[2], image.shape[3]\n",
        "        if scale != self.identity_param:\n",
        "            image = ttach.functional.scale(\n",
        "                image,\n",
        "                scale,\n",
        "                interpolation=self.interpolation,\n",
        "                align_corners=self.align_corners,\n",
        "            )\n",
        "            if image.shape[2]>=image_h:\n",
        "                image=ttach.functional.center_crop(image, image_h, image_w)\n",
        "            else :\n",
        "                image=ttach.functional.resize(image, (image_h,image_w))\n",
        "        return image"
      ],
      "metadata": {
        "id": "F5ooQbUf1QPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tta_transforms = ttach.Compose(\n",
        "    [\n",
        "        ttach.Rotate90(angles=[0, 90, 180, 270]),\n",
        "        ttach.Multiply(factors=[0.9, 1, 1.1]),\n",
        "        myScale(scales=[0.9,1, 1.1])\n",
        "    ]\n",
        ")\n",
        "\n",
        "tta_swin_tiny_patch4_window7_224 = ttach.ClassificationTTAWrapper(swin_tiny_patch4_window7_224, tta_transforms)\n",
        "tta_mixnet_s = ttach.ClassificationTTAWrapper(mixnet_s, tta_transforms) \n",
        "tta_efficientnetB2 = ttach.ClassificationTTAWrapper(efficientnetB2, tta_transforms) \n",
        "tta_efficientnetB0 = ttach.ClassificationTTAWrapper(efficientnetB0, tta_transforms) "
      ],
      "metadata": {
        "id": "MJfP9DyExWpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tta_swin_tiny_patch4_window7_224.to(device)\n",
        "tta_swin_tiny_patch4_window7_224.eval()\n",
        "tta_mixnet_s.to(device)\n",
        "tta_mixnet_s.eval()\n",
        "tta_efficientnetB2.to(device)\n",
        "tta_efficientnetB2.eval()\n",
        "tta_efficientnetB0.to(device)\n",
        "tta_efficientnetB0.eval()\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img224,img300 in iter(zip(test_loader224,test_loader300)):\n",
        "\n",
        "        img224 = img224.to(device)\n",
        "        img300 = img300.to(device)\n",
        "\n",
        "        pred1 = tta_swin_tiny_patch4_window7_224(img224)\n",
        "        pred2 = tta_efficientnetB2(img300)\n",
        "        pred3 = tta_efficientnetB0(img300)\n",
        "        pred4 = tta_mixnet_s(img300)\n",
        "\n",
        "        pred = (pred1+pred2+pred3+pred4)/4\n",
        "        \n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ],
      "metadata": {
        "id": "jzLR3_rpxlOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z4Lat0d5qL_"
      },
      "source": [
        "# Make Submission "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKY4nRqZJYzF"
      },
      "outputs": [],
      "source": [
        "label_decoder = {val:key for key, val in label_unique_dir.items()}\n",
        "\n",
        "f_result = [label_decoder[result] for result in f_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M1ziKV90xp-"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv(\"./data/sample_submission.csv\")\n",
        "\n",
        "submission[\"label\"] = f_result\n",
        "\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"swin_tiny_patch4_window7_224+efficientnet-b2+efficientnet-b0+mixnet_s__2.csv\", index = False)"
      ],
      "metadata": {
        "id": "dy2L4ILFQTsh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DbRHpKkd5nmP",
        "kK489J6SFrMz",
        "X7SZxCfMxN3k"
      ],
      "machine_shape": "hm",
      "name": "Computer_Vision_이상치_탐지_알고리즘_경진대회_Infernece",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}